<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Portfolio</title>
    <link>/</link>
    <description>Recent content on Portfolio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 02 Oct 2016 22:55:05 -0400</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hello world</title>
      <link>/blog/hello-world/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/hello-world/</guid>
      <description>#Im fixing a hole</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/projects/</link>
      <pubDate>Sun, 02 Oct 2016 22:55:05 -0400</pubDate>
      
      <guid>/projects/</guid>
      <description>Projects Here are some projects I have recently completed:
  Exploratory Data Analysis with Tidyverse Tools
  Modeling, Testing, and Classification
  </description>
    </item>
    
    <item>
      <title>Project 1: Exploratory Data Analysis</title>
      <link>/project1.ethanpieniazekweb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/project1.ethanpieniazekweb/</guid>
      <description>After scouring for hours on Kaggle, spreadsheets, and data.gov for this project in search of two interesting datasets that could be related by a common variable, I ended up stumbling across some interesting stuff while not even actively searching. After reading that “Uncut Gems” had the seventh most f-bombs in movie history, I searched along these lines and found a table on wikipedia that was 144 observations long. The table included the name and year of the film, rank relative to one another concerning the total number of f-bombs, total f-bombs, total minutes, source, and f-bombs per minute.</description>
    </item>
    
    <item>
      <title>Project 2: Modeling</title>
      <link>/project2.ethanpieniazekweb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/project2.ethanpieniazekweb/</guid>
      <description>library(tidyverse) library(lmtest) library(sandwich) covid &amp;lt;- read.csv(&amp;quot;//Users/bitoFLO/Desktop/Website/content/1_county_level_confirmed_cases(1).csv&amp;quot;, header = T, na.strings = c(&amp;quot;&amp;quot;, &amp;quot;NA&amp;quot;)) covid &amp;lt;- covid %&amp;gt;% na.omit() The dataset I found collected by John Hopkins University (Johns Hopkins University’s COVID-19 tracking project) contains data relevant to the novel coronavirus pertaining to the United States. The data concerns confirmed cases, deaths, confirmed cases per 100,000 people, and deaths per 100,000 people for various counties in each state as of April 21st, 2020.</description>
    </item>
    
  </channel>
</rss>